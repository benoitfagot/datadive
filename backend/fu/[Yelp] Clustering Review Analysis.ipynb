{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "pathModulesES = '../sauceforyall/'\n",
    "sys.path.append(pathModulesES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elasticsearch Query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yelpquery import YelpQuery\n",
    "from pandasticsearch import Select\n",
    "ye = YelpQuery()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Others**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Index name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_business = \"yelp-business*\"\n",
    "index_review = \"yelp-review*\"\n",
    "index_tip = \"yelp-tip*\"\n",
    "index_user = \"yelp-user*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/hongphuc95/notebookteam/dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve all the reviews from the last 3 years, this helps reduce the volume of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = pd.read_json(data_path + \"cleaned/restaurant_review_cleaned_2018.json\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Handle missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are businesses that don't have any reviews in the particular year we're looking for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id       False\n",
       "name              False\n",
       "categories        False\n",
       "city              False\n",
       "state             False\n",
       "business_stars    False\n",
       "cool               True\n",
       "useful             True\n",
       "funny              True\n",
       "stars              True\n",
       "review_id          True\n",
       "user_id            True\n",
       "date               True\n",
       "text               True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = df_review.dropna(subset=[\"review_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712379, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oITu5Qwnmv0hsEMc21XjXw</td>\n",
       "      <td>The Chef's Table at Quickhatch</td>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AEbyPwGD6_A9i3R0lwqrUA</td>\n",
       "      <td>XL1D6UF2Bl3tmkcfqxgLJg</td>\n",
       "      <td>2018-02-18 13:27:12</td>\n",
       "      <td>We be in love with Quickhatch ... the food, Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oITu5Qwnmv0hsEMc21XjXw</td>\n",
       "      <td>The Chef's Table at Quickhatch</td>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ybqOQcrY5hM3zWo4lSduUA</td>\n",
       "      <td>WcrRl0U659RxXHkKANZSdQ</td>\n",
       "      <td>2018-01-20 22:20:38</td>\n",
       "      <td>Phenomenal dinner last night. The chef really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oITu5Qwnmv0hsEMc21XjXw</td>\n",
       "      <td>The Chef's Table at Quickhatch</td>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>rnarbYk8Nlbxfmrid78Jug</td>\n",
       "      <td>XmYUCXBf5LxSFppvNmfxFA</td>\n",
       "      <td>2018-01-15 16:54:34</td>\n",
       "      <td>Our group of eight have an outstanding multi-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oITu5Qwnmv0hsEMc21XjXw</td>\n",
       "      <td>The Chef's Table at Quickhatch</td>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7AQcBhn6XQ7-M0QOme8K7g</td>\n",
       "      <td>xZknZsB-yxEQbI8JLollXw</td>\n",
       "      <td>2018-01-24 12:47:42</td>\n",
       "      <td>it be restaurant week. we read over the menu l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C2wtzldZi02IwFSp8zgT0w</td>\n",
       "      <td>Kona Grill Corporate Office</td>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5pk-1aFG1nF0-OsZqVkOeA</td>\n",
       "      <td>vwi68eg4bmJHMSYq3jP2OQ</td>\n",
       "      <td>2018-01-14 07:05:43</td>\n",
       "      <td>Had dinner with our friend from the west valle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                            name     categories  \\\n",
       "2  oITu5Qwnmv0hsEMc21XjXw  The Chef's Table at Quickhatch  [Restaurants]   \n",
       "3  oITu5Qwnmv0hsEMc21XjXw  The Chef's Table at Quickhatch  [Restaurants]   \n",
       "4  oITu5Qwnmv0hsEMc21XjXw  The Chef's Table at Quickhatch  [Restaurants]   \n",
       "5  oITu5Qwnmv0hsEMc21XjXw  The Chef's Table at Quickhatch  [Restaurants]   \n",
       "6  C2wtzldZi02IwFSp8zgT0w     Kona Grill Corporate Office  [Restaurants]   \n",
       "\n",
       "         city state  business_stars  cool  useful  funny  stars  \\\n",
       "2  Pittsburgh    PA             4.0   0.0     0.0    0.0    5.0   \n",
       "3  Pittsburgh    PA             4.0   0.0     1.0    0.0    5.0   \n",
       "4  Pittsburgh    PA             4.0   0.0     0.0    0.0    5.0   \n",
       "5  Pittsburgh    PA             4.0   0.0     1.0    0.0    1.0   \n",
       "6  Scottsdale    AZ             2.0   1.0     2.0    0.0    4.0   \n",
       "\n",
       "                review_id                 user_id                date  \\\n",
       "2  AEbyPwGD6_A9i3R0lwqrUA  XL1D6UF2Bl3tmkcfqxgLJg 2018-02-18 13:27:12   \n",
       "3  ybqOQcrY5hM3zWo4lSduUA  WcrRl0U659RxXHkKANZSdQ 2018-01-20 22:20:38   \n",
       "4  rnarbYk8Nlbxfmrid78Jug  XmYUCXBf5LxSFppvNmfxFA 2018-01-15 16:54:34   \n",
       "5  7AQcBhn6XQ7-M0QOme8K7g  xZknZsB-yxEQbI8JLollXw 2018-01-24 12:47:42   \n",
       "6  5pk-1aFG1nF0-OsZqVkOeA  vwi68eg4bmJHMSYq3jP2OQ 2018-01-14 07:05:43   \n",
       "\n",
       "                                                text  \n",
       "2  We be in love with Quickhatch ... the food, Ch...  \n",
       "3  Phenomenal dinner last night. The chef really ...  \n",
       "4  Our group of eight have an outstanding multi-c...  \n",
       "5  it be restaurant week. we read over the menu l...  \n",
       "6  Had dinner with our friend from the west valle...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clustering the review for all the restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = df_review[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train/Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_train, comment_test = train_test_split(comments, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 NLP Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer = 'word', stop_words = 'english', \n",
    "                             lowercase = True, max_features = 5000,\n",
    "                             ngram_range = (1, 1)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with the users comments vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = vectorizer.fit(comment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_train_vec = vectorizer.transform(comment_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction, in layman term we try to get the vocabulary of your TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform all the original reviews using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_vec = vectorizer.transform(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Cluster reviews with K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two classes guess**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test our assumption that we can really split the behaviour of all the restaurant reviews by positive/negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "clf_km = KMeans(n_clusters = n_clusters)\n",
    "clf_km.fit(comment_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = clf_km.predict(comment_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspect the centroids**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We inspect the centroids to have a better idea what topics KMeans has figured out.\n",
    "\n",
    "The next step is reverse the vector space back to word space to make that redeable by humains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.23271364e-04, 2.76300209e-04, 8.46512122e-03, ...,\n",
       "        3.54384110e-04, 1.16711320e-04, 8.27614753e-05],\n",
       "       [1.52693934e-05, 7.38953324e-05, 3.85173994e-03, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_km.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top features per cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we show the most relevant features in each cluster, 20 per cluster seems ought to be enough. We're interested in the most present words ake feature with the greatest represention in the centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sort each centroid vector to find the top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 05, 100, 12, 0pm, 36, 2am, 3am, 2x, 45pm, 21, 16, 1000, 10pm, 120, 48, 13, absolute, 95, 75, 34, 38, 10am, 30am, 44, 8pm, 32, 1st, 2017, 28, 3x, 7pm, 50, absurd, 150, 2pm, 300, 5th, 22, 25, 2nd, 80, 29, 19, 1pm, 18, 2018, 10, 42, 15, 6pm, 30min, 39, 99, aburi, 30, 9am, 40, 1am, 90, 5pm, abundant, 101, 500, 23, absolutely, 9pm, 8oz, abundance, 24, acai, 27, 55, 7th, 17, 65, 20, 11, 70, 3rd, 4th, 15pm, 45, 49, able, 14, 31, 33, 200, 35, 60, 21st, ability, 130, 85, ac, 30pm, a1, 26, 4pm, 3pm\n",
      "1: 05, 0pm, 10, 100, 1000, absurd, 32, 30am, 75, 3x, 1st, 38, 36, 21, 120, 13, 44, 30min, 95, 15, 19, 28, 90, 80, 2x, 12, 50, 10am, absolute, 34, 45pm, 3am, 18, 2017, 16, 2pm, 2am, 7pm, 10pm, 48, 1pm, 2018, 8pm, 150, 300, 24, 11, 29, 25, 42, 3rd, 22, 5pm, 6pm, 7th, 1am, 2nd, 39, 40, abundant, 30, 5th, 99, 101, 27, 55, 9am, 8oz, 65, aburi, 23, 500, 70, absolutely, abundance, 9pm, able, 17, 4th, 20, 31, 15pm, acai, 200, 49, 33, 45, 21st, 14, 30pm, 35, 85, ac, a1, 130, ability, 26, 4pm, 3pm, 60\n"
     ]
    }
   ],
   "source": [
    "top_features_cluster = list()\n",
    "n_clusters = clf_km.n_clusters\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    feature_sorted = np.argsort(clf_km.cluster_centers_[i][::-1][:100])\n",
    "    top_features_cluster.append(feature_sorted)\n",
    "    \n",
    "for num, centroid in enumerate(top_features_cluster):\n",
    "    word_centroid = \", \".join(words[i] for i in centroid)\n",
    "    print(\"%d: %s\" % (num, word_centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
